name: Daily Scraper & Extraction Pipeline

on:
  schedule:
    # Run daily at 06:00 UTC
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      scrape:
        description: 'Run scrapers'
        required: true
        default: true
        type: boolean
      extract:
        description: 'Run extraction'
        required: true
        default: true
        type: boolean
      limit:
        description: 'Extraction limit'
        required: false
        default: 50
        type: number

jobs:
  pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Pipeline
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python -m pipeline.orchestrator --full --limit 50

      - name: Upload logs
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: pipeline-logs
          path: logs/
          retention-days: 7
